#!/bin/bash
#
# ENVIRONMENT SPECIFIC SETTINGS
#

#-----------------------------------------------
# SYSTEM - SISU - SUPERCOMPUTER
#-----------------------------------------------
# Number of cores per node
SYS_CPUSPERNODE=24

# Sisu nodes are not shared for jobs, reserve full nodes (rounded up) 
# if CPUs given
if [ ! -z $CPUSTOT ]; then
    NNODES=1
    cpus=$CPUSTOT
    while [ false ]; do
	cpus=$(($cpus - $SYS_CPUSPERNODE))
	if [ $cpus -le 0 ]; then
	    break
	else
	    NNODES=$(($NNODES+1))
	fi
    done
else # Calc CPUS for EXPTIME
    CPUSTOT=$(echo "$NNODES * $SYS_CPUSPERNODE" | bc)
fi
export CPUSTOT

# Path structure
WORK=$WRKDIR/openEPS/${EXPL}_sisu
SCRI=$WORK/scripts
DATA=$WORK/data
SRC=$WORK/configs
TMPDIR=$WORK
export WORK SCRI DATA SRC TMPDIR

# Estimate bulk job time if TIMEFORMODEL given instead of EXPTIME
if [ -z $EXPTIME ]; then
    mandtg=$WORK/mandtg

    totperday=$(echo "$TIMEFORMODEL * $ENS" | bc)
    totdays=$($mandtg $EDATE - $SDATE)
    totdays=$(echo "$totdays / $DSTEP + 1" | bc)
    totmins=$(echo "$totperday * $totdays" | bc)
    parallels=$(echo "$CPUSTOT / $CPUSPERMODEL" | bc)
    tottime=$(echo "$totmins / $parallels" | bc)

    modul=$(printf '%02d' $(($tottime % 60)))
    EXPTIME=$(echo "$tottime / 60" | bc)":$modul:00"
fi
export EXPTIME


# Match batchjob queue with requested resources
if [ -z $BATCHQUEUE ]; then
    if [ $NNODES -le 2 ]; then
	BATCHQUEUE=test
    else
	BATCHQUEUE=small
    fi
fi


# Batch job specification
# If unspecified or false, run on local resources
SEND_AS_SINGLEJOB="true" # send whole main.bash to queue
SEND_AS_MULTIJOB="false"   # only send run.bash to queue
line1="#SBATCH -p $BATCHQUEUE"       # batchjob queue
line2="#SBATCH -J $EXPS"             # name
line3="#SBATCH -t $EXPTIME"          # time reservation
line4="#SBATCH -N $NNODES"           # nodes tot
line6='#SBATCH -o out'               # where to write output 
line7='#SBATCH -e err'               # where to write error

# Load modules
export CONDA_ENVS_PATH=$WRKDIR/DONOTREMOVE/sisu-conda-envs
#module load openifs/40r1v1.1
module load eccodes
module load bioconda
source activate /wrk/lautuppi/DONOTREMOVE/sisu-conda-envs/eppes

#-----------------------------------------------
# MODEL SPECIFIC DIRS AND SETTINGS
#-----------------------------------------------
# Default model version
if [ -z $OIFSv ]; then
    OIFSv=40r1v1
else
    if [ ! $OIFSv == "40r1v1"]; then
	echo "OIFS version $OIFSv NOT supported in this env, using default instead"
	OIFSv=40r1v1
    fi
fi

# Default model path
if [ -z $MODEL_EXE ]; then
    if [ $OIFSv == "38r1v04" ]; then
	echo "OIFS $OIFSv NOT COMPILED"
	exit
    else
	MODEL_EXE=/proj/atm/lauri/oifs40r1v1/cce/8.5.6/bin/master.exe
    fi
fi

# Paths for model
GRIB_SAMPLES_PATH=/appl/climate/eccodes/2.7.3/CRAY/8.5/share/eccodes/ifs_samples/grib1_mlgrib2

# Initial states
INIBASEDIR=/wrk/project_2001029/OIFS_INI

# Paths to initial states
IFSDATA=$INIBASEDIR

export MODEL_EXE
export INIBASEDIR IFSDATA IFSDATA2 GRIB_SAMPLES_PATH
export LD_LIBRARY_PATH

# Increase stack memory (model may crash with SEGV otherwise)
ulimit -s unlimited

# Grib-tools needed
export GRIBTOOLS=/appl/climate/eccodes/2.7.3/CRAY/8.5/bin

# --------------------------------------------------------------
# REQUIRED DIRS AND SCRIPTS
# --------------------------------------------------------------
# Model structure and programs that are needed
REQUIRE_NAMEL="namelist_general.bash namelist_${OIFSv}.bash"

# --------------------------------------------------------------
# TESTING
# --------------------------------------------------------------
# Vital paths that must exist
REQUIRE_PATHS="$REQUIRE_PATHS MODEL_EXE INIBASEDIR IFSDATA GRIB_SAMPLES_PATH"

# Vital variables that must exist	
REQUIRE_VARS="$REQUIRE_VARS WORK SCRI DATA SRC TMPDIR OMP_NUM_THREADS DR_HOOK"
